{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from Bio.PDB import PDBParser\n",
    "from Bio.PDB.PDBExceptions import PDBConstructionWarning\n",
    "\n",
    "biopython_parser = PDBParser()\n",
    "\n",
    "def parse_pdb_from_path(path):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\", category=PDBConstructionWarning)\n",
    "        structure = biopython_parser.get_structure('random_id', path)\n",
    "        rec = structure[0]\n",
    "    return rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6ckl\n",
      "['PDBBind_processed/6ckl']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "folder_paths = []\n",
    "for root, dirs, files in os.walk(\"PDBBind_processed\"):\n",
    "    for dir in dirs:\n",
    "        folder_paths.append(os.path.join(root, dir))\n",
    "        print(dir)\n",
    "\n",
    "\n",
    "print(folder_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain 0: A\n",
      "Chain 1: B\n",
      "20\n",
      "[['C', '301'], ['A', '703'], ['B', '301']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31062/2399064203.py:113: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_multiple = df_multiple.append(new_row, ignore_index=True)\n",
      "/tmp/ipykernel_31062/2399064203.py:113: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_multiple = df_multiple.append(new_row, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C 301\n",
      "A 703\n",
      "B 301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31062/2399064203.py:113: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_multiple = df_multiple.append(new_row, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "from rdkit import Chem\n",
    "from rdkit import Chem\n",
    "\n",
    "df_multiple = pd.DataFrame(columns=['Protein', 'Ligand', 'Chain', 'Residue', 'Ligand_file', 'Protein_file'])\n",
    "df = pd.DataFrame()\n",
    "\n",
    "ligand_file = \"6ckl_ligand.mol2\"\n",
    "# parse\n",
    "ligand_file = \"6ckl_ligand.mol2\"\n",
    "protein_file = \"6ckl_protein_processed.pdb\"\n",
    "# Parse the protein file\n",
    "pdbbind_rec = parse_pdb_from_path(protein_file)\n",
    "\n",
    "# Check if the protein was successfully parsed\n",
    "if pdbbind_rec is not None:\n",
    "    # Get the number of chains\n",
    "\n",
    "\n",
    "    for i, chain in enumerate(pdbbind_rec):\n",
    "        print(f\"Chain {i}: {chain.id}\")\n",
    "    # num_chains = pdbbind_rec.GetNumChains()\n",
    "    # print(\"Number of chains:\", num_chains)\n",
    "    \n",
    "    # Get the names of the chains\n",
    "    # chain_names = [chain.GetChainID() for chain in protein_mol.GetChains()]\n",
    "    # print(\"Chain names:\", chain_names)\n",
    "else:\n",
    "    print(\"Failed to parse the protein file.\")\n",
    "\n",
    "# exit(0)\n",
    "\n",
    "\n",
    "# Parse the ligand file\n",
    "mol = Chem.MolFromMol2File(ligand_file)\n",
    "atom_names = []\n",
    "atom_coordinates = []\n",
    "atom_residues = []\n",
    "\n",
    "# Iterate over the atoms in the molecule\n",
    "for atom in mol.GetAtoms():\n",
    "    # Get the name of the atom\n",
    "    atom_name = atom.GetSymbol()\n",
    "    atom_names.append(atom_name)\n",
    "    \n",
    "    # Get the coordinates of the atom\n",
    "    # atom_coordinate = atom.get_vector()\n",
    "    # atom_coordinates.append(atom_coordinate)\n",
    "    \n",
    "    # Get the residue of the atom\n",
    "    # atom_residue = atom.GetResidue().GetName()\n",
    "    # atom_residues.append(atom_residue)\n",
    "\n",
    "# Print the atom names, coordinates, and residues\n",
    "for name, coordinate, residue in zip(atom_names, atom_coordinates, atom_residues):\n",
    "    print(f\"Atom Name: {name}, Coordinate: {coordinate}, Residue: {residue}\")\n",
    "\n",
    "\n",
    "# Check if the ligand was successfully parsed\n",
    "if mol is not None:\n",
    "    atoms = mol.GetNumAtoms()\n",
    "    # Get the name of atom\n",
    "    print(atoms)\n",
    "    pass\n",
    "else:\n",
    "    print(\"Failed to parse the ligand file.\")\n",
    "\n",
    "\n",
    "# URL of the webpage\n",
    "url = \"https://www.rcsb.org/ligand-validation/6CKL/DAN\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Get the HTML content\n",
    "    html_content = response.text\n",
    "    \n",
    "\n",
    "    pdb = \"6CKL\"\n",
    "    lig = \"DAN\"\n",
    "\n",
    "    # Construct the pattern using the pdb and lig variables\n",
    "    pattern = f\"{pdb}_{lig}_\\\\w+\"\n",
    "\n",
    "    # Find all matches of the pattern in the HTML content\n",
    "    matches = re.findall(pattern, html_content)\n",
    "\n",
    "    # Print the matched strings\n",
    "    unique_matches = list(set(matches))\n",
    "    extracted_parts = [part.split(\"_\")[2:] for part in unique_matches]\n",
    "    print(extracted_parts)\n",
    "    if(len(extracted_parts) > 1):\n",
    "        for part in extracted_parts:\n",
    "            auth_asym_id = part[0]\n",
    "            auth_seq_id = part[1]\n",
    "            url_lig = f\"https://models.rcsb.org/v1/{pdb}/ligand?auth_asym_id={auth_asym_id}&auth_seq_id={auth_seq_id}&encoding=mol2\"\n",
    "            resp = requests.get(url_lig)\n",
    "            if resp.status_code == 200:\n",
    "                sub_dir = os.path.join('PDBBind_processed', pdb.lower())\n",
    "                os.makedirs(sub_dir, exist_ok=True)\n",
    "                with open(os.path.join(sub_dir, f\"{pdb}_{lig}_{auth_asym_id}_{auth_seq_id}.mol2\"), \"w\") as f:\n",
    "                    new_row = {'Protein': pdb, 'Ligand': lig, 'Chain': auth_asym_id, 'Residue': auth_seq_id,\n",
    "                                                       'Ligand_file': os.path.join(sub_dir, f\"{pdb}_{lig}_{auth_asym_id}_{auth_seq_id}.mol2\"),\n",
    "                                                       'Protein_file': os.path.join(sub_dir, f\"{pdb.lower()}_protein_processed.pdb\")\n",
    "                                                       }\n",
    "                    df_multiple = df_multiple.append(new_row, ignore_index=True)\n",
    "                    f.write(resp.text)\n",
    "\n",
    "    for part in extracted_parts:\n",
    "        chain = part[0]\n",
    "\n",
    "        print(part[0], part[1])\n",
    "else:\n",
    "    print(\"Failed to retrieve the webpage.\")\n",
    "\n",
    "df_multiple.to_csv('PDBBind_processed/multiple_ligands.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmol\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGetProp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mName\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Name'"
     ]
    }
   ],
   "source": [
    "mol.GetProp(\"Name\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ligand_file = \"6ckl_ligand.mol2\"\n",
    "\n",
    "mol = Chem.MolFromMol2File(ligand_file)\n",
    "atom_names = []\n",
    "atom_coordinates = []\n",
    "atom_residues = []\n",
    "\n",
    "subgraphs = Chem.FindAllSubgraphsOfLengthN(mol, 3)\n",
    "\n",
    "# Iterate over the atoms in the molecule\n",
    "for atom in mol.GetAtoms():\n",
    "    # Get the name of the atom\n",
    "    try:\n",
    "        residue_name = atom.GetProp('_TriposResidueName')\n",
    "        atom_residues.append(residue_name)\n",
    "    except KeyError:\n",
    "        atom_residues.append(None)\n",
    "    # print(atom_name)\n",
    "    # molecule_name = atom.GetProp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atom_residues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.rcsb.org/3d-view/6CKL\"\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200:\n",
    "    html_content = response.text\n",
    "    pattern = \"[\"\n",
    "    matches = re.findall(pattern, html_content)\n",
    "    print(matches)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
